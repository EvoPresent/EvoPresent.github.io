<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/logo.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
         <img src="./static/figure/logo1.png" alt="Logo" style="height: 120px;  margin-top: 6px;" />
            <h1 class="title publication-title" style="font-size: 2.5rem; margin-top: 10px;">
            More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models
          </h1>


  <div class="is-size-5 publication-authors">
  <div>
    <span class="author-block">
      <a href="">Chengzhi Liu*</a><sup>1</sup>,
    </span>
    <span class="author-block">
      <a href="">Zhongxing Xu*</a><sup>1</sup>,
    </span>
    <span class="author-block">
      <a href="">Qingyue Wei</a><sup>2</sup>,
    </span>
    <span class="author-block">
      <a href="">Juncheng Wu</a><sup>3</sup>,
    </span>
  </div>
  <div>
    <span class="author-block">
      <a href="">James Zoou</a><sup>2</sup>,
    </span>
    <span class="author-block">
      <a href="">Xin Eric Wang</a><sup>1,3</sup>,
    </span>
    <span class="author-block">
      <a href="">Yuyin Zhou</a><sup>3</sup>,
    </span>
    <span class="author-block">
      <a href="">Sheng Liu</a><sup>2</sup>
    </span>
  </div>
    </div>

<div class="is-size-5 publication-authors" style="text-align: center;">
  <span><sup>1</sup>UC Santa Barbara, <sup>2</sup>Stanford University, <sup>1</sup>UC Santa Cruz</span>
</div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.06172"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/eric-ai-lab/MSSBench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/kzhou35/mssbench/tree/main"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser"  style="background-color: #f2f2f2;">
  <div class="container is-max-desktop">
    <div class="hero-body">

    </div>
  </div>
</section>


<section class="section"  style="background-color: #f2f2f2;">
  <div style="display: flex; justify-content: center;">
    <figure style="width: 50%; text-align: center; margin-left: 5%; margin-top: -35px;">
      
      <!-- 图片 -->
      <img 
        src="./static/figure/intro.png" 
        alt="image" 
        style="width: 90%; height: auto;" 
        loading="lazy" 
      />
      
      <figcaption 
        style="width: 90%; margin: 0.5rem auto 0; font-size: 0.95rem; text-align: left;">
          <strong>(a)</strong> Example of outputs from a reasoning model and a non-reasoning model on a perception task. 
  <span style="color: red;">Red highlights indicate visual hallucination.</span> 
  <em>Multimodal reasoning models are generally more prone to amplifying hallucinations during the reasoning process compared to their non-reasoning counterparts.</em> 
  <strong>(b)</strong> Performance of different models on reasoning and perception tasks in the <em>RH-Bench</em> dataset. Better performing models are positioned in the upper right corner. 
  <em>Baseline non-reasoning models of varying scales typically exhibit weaker reasoning capabilities and fewer hallucination, whereas reasoning models display the opposite trend.</em>

    </figure>
  </div>
</section>

  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
             Test-time compute has empowered multimodal large language models to generate extended reasoning chains, yielding strong performance on tasks such as multimodal math reasoning. However, we observe that this improved reasoning ability often comes with increased hallucination: as generations become longer, models tend to drift away from image-grounded content and rely more on language priors. Attention analysis reveals that longer reasoning chains reduce focus on visual inputs, contributing to hallucination. To systematically study this phenomenon, we introduce <em>RH-AUC</em>, a metric that quantifies how a model's perception accuracy changes with reasoning length, enabling evaluation of whether the model preserves visual grounding while reasoning. We also release <em>RH-Bench</em>, a diagnostic benchmark covering diverse multimodal tasks, designed to jointly assess the balance of reasoning ability and hallucination. We find that <em>(i)</em> larger models generally exhibit a better balance between reasoning and perception; <em>(ii)</em> reasoning and perception balance depends more on the types and domains of the training data than its volume. Our findings highlight the need for evaluation frameworks that account for both reasoning quality and perceptual reliability.

          </p>
        </div>
      </div>
    </div>
 
<!-- </section> -->
       <div class="columns is-centered has-text-centered" style="margin-top: 2rem;">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Multimodal Reasoning Can Amplify Visual Hallucination</h2>
      </div>
      </div>
        
<section class="section"  style="background-color: #f2f2f2;">
  <div style="display: flex; justify-content: center;">
    <figure style="width: 50%; text-align: center; margin-left: 5%; margin-top: -35px;">
      
      <!-- 图片 -->
      <img 
        src="./static/figure/radar.png" 
        alt="image" 
        style="width: 90%; height: auto;" 
        loading="lazy" 
      />
      
      <figcaption 
        style="width: 90%; margin: 0.5rem auto 0; font-size: 0.95rem; text-align: left;">
          <strong>(a)</strong> Example of outputs from a reasoning model and a non-reasoning model on a perception task. 
  <span style="color: red;">Red highlights indicate visual hallucination.</span> 
  <em>Multimodal reasoning models are generally more prone to amplifying hallucinations during the reasoning process compared to their non-reasoning counterparts.</em> 
  <strong>(b)</strong> Performance of different models on reasoning and perception tasks in the <em>RH-Bench</em> dataset. Better performing models are positioned in the upper right corner. 
  <em>Baseline non-reasoning models of varying scales typically exhibit weaker reasoning capabilities and fewer hallucination, whereas reasoning models display the opposite trend.</em>

    </figure>
  </div>
</section>


<div class="columns is-centered has-text-centered" style="margin-top: 0rem;">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Why Reasoning Models Amplify Hallucinations?</h2>
  </div>
</div>
    
 <section class="section"  style="background-color: #f2f2f2;">
  <div class="columns is-centered" style="margin-bottom: 0.25rem;">
    <!-- 单图居中显示 -->
    <div class="column is-half" style="text-align: center;">
      <figure class="image">
        <img 
          src="./static/figure/heatmap.png" 
          alt="image" 
          style="width: 230%; height: auto;"  
          loading="lazy"
        />
        <figcaption style="text-align: center;">
          Figure 2. Presentation of MSSBench across four domains and ten secondary categories in Chat and Embodied tasks.
        </figcaption>
      </figure>
    </div>
  </div>
</section>

 <section class="section"  style="background-color: #f2f2f2;">
  <div class="columns is-centered" style="margin-bottom: 0.25rem;">
    <!-- 单图居中显示 -->
    <div class="column is-half" style="text-align: center;">
      <figure class="image">
        <img 
          src="./static/figure/overthinking.png" 
          alt="image" 
          style="width: 150%; height: auto;"  
          loading="lazy"
        />
        <figcaption style="text-align: center;">
          Figure 2. Presentation of MSSBench across four domains and ten secondary categories in Chat and Embodied tasks.
        </figcaption>
      </figure>
    </div>
  </div>
</section>


    
<div class="columns is-centered has-text-centered" style="margin-top: -0.5rem;">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Effects of Reasoning Length on Reasoning-Hallucination Balance</h2>
      </p>
        We assess the performance of 8 leading multimodal large language models (MLLMs) on our MSS benchmark.
      </p>
      </div>
      </div>
    
<section class="section" style="margin-top: -2.6rem;"  style="background-color: #f2f2f2;">
  <figure class="image is-centered" style="width: 80%; margin: 0 auto 1rem; text-align: center;">
    <img 
      src="./static/figure/length.png" 
      alt="image" 
      style="width: 150%; height: auto;" 
      loading="lazy"
    />
    <figcaption style="text-align: center;">
      Table 1. Accuracy of MLLMs under instruction following setting. All of the MLLMs struggle to respond with safety awareness under unsafe situations and perform even worse in Embodied Task.
    </figcaption>
  </figure>
</section>

    
<section class="section" style="margin-top: -1.5rem;"  style="background-color: #f2f2f2;">
  <div class="content has-text-centered">
    <p>
   We identify three main reasons for MLLM's poor performance on the MSS benchmark: lack of explicit safety reasoning, visual understanding, and situational safety judgment. To validate these hypotheses, we design four distinct evaluation settings: (1) explicit safety reasoning for user queries, (2) explicit safety reasoning for user intents, (3) explicit safety reasoning for user intents with self-captioning, and (4) explicit safety reasoning for user intents using ground-truth situation information. 
    </p>
  </div>
</section>

<div style="border: 2px solid #4A90E2; border-radius: 10px; overflow: hidden; width: fit-content; max-width: 100%;">
  <div style="background-color: #A0C4EF; padding: 8px 12px; font-weight: bold; color: #1b4f91;">
    Takeaway 2: Moderate Reasoning Length Strikes the Best Reasoning-Hallucination Balance
  </div>
  <div style="background-color: #E8F1FC; padding: 10px 15px; font-style: italic; border-top: 1px solid #4A90E2;">
    <span>
      Reasoning length exerts a non-monotonic effect on model performance: both insufficient and excessive reasoning degrade accuracy, and the optimal length is task-dependent.
    </span>
  </div>
</div>



<div class="columns is-centered has-text-centered" style="margin-top: 1rem;">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Evaluation on the Reasoning-Hallucination Balance</h2>
      </div>
      </div>
    
<section class="section"  style="background-color: #f2f2f2;">
  <figure class="image is-centered" style="width: 100%; margin: 0 auto 2rem; text-align: center;">
    <img 
      src="./static/agent.png" 
      alt="image" 
      style="width: 100%; height: auto;" 
      loading="lazy" 
    />
    <figcaption style="text-align: center;">
      Figure 5. Workflow of our Multi-Agent framework for enhancing situational safety in user queries, incorporating Intent Reasoning, Safety Judgment, QA and Visual Understanding agents.
    </figcaption>
  </figure>
</section>




<!-- 固定布局的 BibTeX 部分 -->
<section class="section" id="BibTeX">
  <div class="container content" style="max-width: 800px; margin: 0 auto;">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{zhou2024multimodalsituationalsafety,
      title={Multimodal Situational Safety}, 
      author={Kaiwen Zhou and Chengzhi Liu and Xuandong Zhao and Anderson Compalas and Dawn Song and Xin Eric Wang},
      year={2024},
      eprint={2410.06172},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.06172}, 
}</code></pre>
  </div>
</section>


